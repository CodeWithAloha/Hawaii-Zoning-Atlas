{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc235dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a09b62d",
   "metadata": {},
   "source": [
    "### Define helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2818b12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert sq m to acres\n",
    "m2acres = lambda x: x * 0.00024711\n",
    "\n",
    "# Function to generate zone ID from state,\n",
    "# jurisdiction name & abbreviated district name\n",
    "def create_id(s, j, ad):\n",
    "    s = str(s).upper()\n",
    "    j = str(j).split('-')[0].strip().upper().split('/')[0]\n",
    "    ad = str(ad).replace('-', '').replace(' ', '').upper()\n",
    "    return f'{s}--{j}--{ad}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f64e13",
   "metadata": {},
   "source": [
    "### Define a function that reads and cleans up every GIS file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4163a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_zoning_file(filepath):\n",
    "    try:\n",
    "        # Read GIS file into dataframe\n",
    "        gdf = (gpd\n",
    "               .read_file(filepath)\n",
    "               .filter(['State', 'Jurisdiction', 'AbbreviatedDistrict', 'geometry'])\n",
    "               .dropna(subset=['geometry']) # remove null geometries\n",
    "               .to_crs('EPSG:4326') # set projection to WGS 84 (lat/lon)\n",
    "              )\n",
    "        # Rename districts with no names to \"Not Zoned\"\n",
    "\n",
    "        gdf.AbbreviatedDistrict = gdf.AbbreviatedDistrict.fillna('Not Zoned')\n",
    "\n",
    "        # Create an ID column that combines jurisdiction and zoning name\n",
    "        gdf['id'] = gdf.apply(\n",
    "            lambda r: create_id(r.State, r.Jurisdiction, r.AbbreviatedDistrict), axis=1\n",
    "        )\n",
    "\n",
    "        # Calculate area (in acres) for each geometry\n",
    "        gdf['ZoneAcres'] = (gdf\n",
    "                            .to_crs('EPSG:6933') # reproject to equal area\n",
    "                            .geometry.area\n",
    "                            .apply(m2acres)\n",
    "                           )\n",
    "\n",
    "        # Calculate total area by zone\n",
    "        total_area_by_zone = (gdf\n",
    "                              .groupby('id')\n",
    "                              ['ZoneAcres']\n",
    "                              .sum()\n",
    "                             )\n",
    "\n",
    "        # Combine (dissolve) geometries by zone\n",
    "        gdf = gdf.dissolve(by='id')\n",
    "        gdf.ZoneAcres = total_area_by_zone # assign new total areas\n",
    "\n",
    "        # Move `id` from index to column\n",
    "        gdf = gdf.reset_index()\n",
    "\n",
    "        return gdf\n",
    "               \n",
    "    except:\n",
    "        print(f\"Error when reading {filepath}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b25662b",
   "metadata": {},
   "source": [
    "### Read all GIS files using the function above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f59a39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder with all GIS files\n",
    "zoning_folder = '../data-pipeline/gis'\n",
    "\n",
    "# Read the folder to get all filenames (ignore hidden files)\n",
    "zoning_files = [x for x in os.listdir(zoning_folder) if x[-5:] == '.gpkg' ]\n",
    "\n",
    "# Read all zones into a single pandas dataframe\n",
    "gdfs = [ read_zoning_file(f\"{zoning_folder}/{filename}\")\n",
    "         for filename in zoning_files ]\n",
    "\n",
    "combined_df = pd.concat( gdfs ).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe535d0",
   "metadata": {},
   "source": [
    "### Derive \"zoneable\" area for each jurisdiction by subtracting federal/state land"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fifty-jumping",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read federal-state-land GeoJSON\n",
    "fed_state_land = gpd.read_file(\n",
    "    '../data-pipeline/federal-state-dissolve.geojson'\n",
    ").to_crs(epsg=4326)\n",
    "\n",
    "\n",
    "\n",
    "# Intersect with all zones\n",
    "# TODO: keep_geom_type=False should be true\n",
    "# Different geometry types in Maui and Fed/state need to reconcile \n",
    "fed_state_land_ = gpd.overlay(\n",
    "    combined_df,\n",
    "    fed_state_land,\n",
    "    keep_geom_type=False,\n",
    "    how='intersection'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94ad2871",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate acres\n",
    "fed_state_land_['FedStateAcres'] = (fed_state_land_\n",
    "    .to_crs(epsg=6933)\n",
    "    .geometry.area\n",
    "    .apply(m2acres)\n",
    ")\n",
    "\n",
    "# Account for repeating zone IDs\n",
    "fed_state_land_ = (fed_state_land_\n",
    "    .dissolve(by='id', aggfunc={'FedStateAcres': 'sum'})\n",
    "    .reset_index()\n",
    "    .filter(['id', 'FedStateAcres'])\n",
    ")\n",
    "\n",
    "# Add federal/state area per zoning district\n",
    "combined_df = combined_df.merge(\n",
    "    fed_state_land_,\n",
    "    on='id',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Calculate municipal (=zoneable) acres\n",
    "combined_df.FedStateAcres = combined_df.FedStateAcres.fillna(0)\n",
    "combined_df['MunicipalAcres'] = combined_df.ZoneAcres -\\\n",
    "    combined_df.FedStateAcres"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "667b5fa8",
   "metadata": {},
   "source": [
    "### Read zoning data from the spreadsheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "abstract-protest",
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Expected 108 fields in line 112, saw 215\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m spreadsheet_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../data-pipeline/hawaii-zoning-data-new.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 3\u001b[0m zoning \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspreadsheet_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskiprows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\\\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;241m.\u001b[39mloc[ :, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mState\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTooltip Notes\u001b[39m\u001b[38;5;124m'\u001b[39m ]\n",
      "File \u001b[0;32m~/anaconda3/envs/hza-data/lib/python3.10/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/hza-data/lib/python3.10/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/hza-data/lib/python3.10/site-packages/pandas/io/parsers/readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    947\u001b[0m )\n\u001b[1;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/hza-data/lib/python3.10/site-packages/pandas/io/parsers/readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[1;32m    610\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[0;32m--> 611\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/hza-data/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1778\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1771\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[1;32m   1772\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1773\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[1;32m   1774\u001b[0m     (\n\u001b[1;32m   1775\u001b[0m         index,\n\u001b[1;32m   1776\u001b[0m         columns,\n\u001b[1;32m   1777\u001b[0m         col_dict,\n\u001b[0;32m-> 1778\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[1;32m   1779\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[1;32m   1780\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1782\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/anaconda3/envs/hza-data/lib/python3.10/site-packages/pandas/io/parsers/c_parser_wrapper.py:230\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlow_memory:\n\u001b[0;32m--> 230\u001b[0m         chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_low_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    231\u001b[0m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[1;32m    232\u001b[0m         data \u001b[38;5;241m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[0;32m~/anaconda3/envs/hza-data/lib/python3.10/site-packages/pandas/_libs/parsers.pyx:808\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/hza-data/lib/python3.10/site-packages/pandas/_libs/parsers.pyx:866\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/hza-data/lib/python3.10/site-packages/pandas/_libs/parsers.pyx:852\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/hza-data/lib/python3.10/site-packages/pandas/_libs/parsers.pyx:1973\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 108 fields in line 112, saw 215\n"
     ]
    }
   ],
   "source": [
    "spreadsheet_path = '../data-pipeline/hawaii-zoning-data-new.csv'\n",
    "\n",
    "zoning = pd.read_csv(spreadsheet_path, skiprows=1)\\\n",
    "    .loc[ :, 'State': 'Tooltip Notes' ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "associate-finnish",
   "metadata": {},
   "outputs": [],
   "source": [
    "zoning['Tooltip Notes'] = zoning['Tooltip Notes'].fillna('')\n",
    "\n",
    "# Remove spaces from column names\n",
    "zoning.columns = [x.strip() for x in zoning.columns.tolist()]\n",
    "\n",
    "# Trim all strings in the dataframe\n",
    "str_columns = zoning.select_dtypes(['object'])\n",
    "zoning[ str_columns.columns ] = str_columns.apply(lambda x: x.str.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440a583c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create id column (to perform linking later)\n",
    "zoning['id'] = zoning.apply(\n",
    "    lambda r: create_id(r.State, r.Jurisdiction, r['Abbreviated District Name']),\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a2121d",
   "metadata": {},
   "source": [
    "### Define a function to convert acre size to a letter category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec9b4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts min lot size into a predefined range\n",
    "#\n",
    "# No size requirement, or 0 acres -> A\n",
    "# 0.01-0.46 acres -> B\n",
    "# 0.47-0.91 acres -> C\n",
    "# 0.92-1.83 acres -> D\n",
    "# 0.92-1.83 acres -> E\n",
    "def min_lot_size(x):\n",
    "    if x != x or x == '': # null\n",
    "        return 'A'\n",
    "    \n",
    "    # x = float( x.split(' ')[0].split('-')[0].replace(',', '') )\n",
    "    \n",
    "    if x == 0:\n",
    "        return 'A'\n",
    "    if x <= 0.46:\n",
    "        return 'B'\n",
    "    if x <= 0.91:\n",
    "        return 'C'\n",
    "    if x <= 1.83:\n",
    "        return 'D'\n",
    "    \n",
    "    return 'E'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887d6336",
   "metadata": {},
   "source": [
    "### Derive new measures in the zoning data\n",
    "This includes \"minimum lot size requirement\" (true/false), \"minimum unit size requirement\" present (true/false), etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa44f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "zoning['AduMaxSizeLimit'] = ~zoning['ADU Max. Size (% of Main Unit)'].isna() | ~zoning['ADU Max. Size (SF)'].isna()\n",
    "\n",
    "# Min Unit Size requirement: transform columns K, O, T, AC into true/false\n",
    "zoning['1MUS'] = ~zoning['1-Family Min. Unit Size (SF)'].isna()\n",
    "zoning['2MUS'] = ~zoning['2-Family Min. Unit Size (SF)'].isna()\n",
    "zoning['3MUS'] = ~zoning['3-Family Min. Unit Size (SF)'].isna()\n",
    "zoning['4MUS'] = ~zoning['4+-Family Min. Unit Size (SF)'].isna()\n",
    "\n",
    "# Any minimum unit size is set? (for tooltip)\n",
    "zoning['MUS'] = zoning['1MUS'] | zoning['2MUS'] | zoning['3MUS'] | zoning['4MUS']\n",
    "\n",
    "# Min Lot Size\n",
    "zoning['1MLS'] = zoning['1-Family Min. Lot (ACRES)'].apply(min_lot_size)\n",
    "# TODO: Clean data\n",
    "zoning['2MLS'] = zoning['2-Family Min. Lot (ACRES)'].apply(min_lot_size)\n",
    "zoning['3MLS'] = zoning['3-Family Min. Lot (ACRES)'].apply(min_lot_size)\n",
    "zoning['4MLS'] = zoning['4+-Family Min. Lot (ACRES)'].apply(min_lot_size)\n",
    "\n",
    "# Elderly housing\n",
    "# 1F Elderly Only —> value from BM column\n",
    "# 2F Elderly Only —> value from BM column\n",
    "# 3F Elderly Only —> Yes if BM = Yes, otherwise value from Y column\n",
    "# 4F Elderly Only —> Yes if BM = Yes, otherwise value from AI column\n",
    "def is_elderly_only(row, col):\n",
    "    if row['Elderly Housing District'] == 'Yes':\n",
    "        return 'Yes'\n",
    "    return row[col]\n",
    "    \n",
    "zoning['1E'] = zoning['Elderly Housing District']\n",
    "zoning['2E'] = zoning['Elderly Housing District']\n",
    "zoning['3E'] = zoning.apply(lambda row: is_elderly_only(row, '3-Family Elderly Housing Only'), axis=1).fillna('No')\n",
    "zoning['4E'] = zoning.apply(lambda row: is_elderly_only(row, '4+-Family Elderly Housing Only'), axis=1).fillna('No')\n",
    "\n",
    "# Create ADU Elderly only\n",
    "zoning['AEld'] = zoning['ADU Elderly Housing Only'].fillna('No')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcab4243",
   "metadata": {},
   "source": [
    "### Generate text for minimum parking requirements\n",
    "This was needed for Connecticut Zoning Atals and may be optional for other atlases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc34d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimum parking required anywhere? for tooltip\n",
    "\n",
    "def parking_text(row):\n",
    "    one = row['1-Family Min. # Parking Spaces']\n",
    "    two = row['2-Family Min. # Parking Spaces Per 2+ BR']\n",
    "    two_ = row['2-Family Min. # Parking Spaces Per Studio or 1BR']\n",
    "    three = row['3-Family Min. # Parking Spaces Per 2+ BR']\n",
    "    three_ = row['3-Family Min. # Parking Spaces Per Studio or 1BR']\n",
    "    four = row['4+-Family Min. # Parking Spaces Per Studio or 1BR']\n",
    "    four_ = row['4+-Family Min. # Parking Spaces Per 2+ BR']\n",
    "    \n",
    "    text = []\n",
    "    if one == one:\n",
    "        text.append(str(one) + ' for 1-family')\n",
    "    if two == two:\n",
    "        text.append(str(two) + ' for 2-family (total)')\n",
    "    if two_ == two_:\n",
    "        text.append(str(two_) + ' for 2-family (per studio/1br)')\n",
    "    if three == three:\n",
    "        text.append(str(three) + ' for 3-family (total)')\n",
    "    if three_ == three_:\n",
    "        text.append(str(three_) + ' for 3-family (per studio/1br)')\n",
    "    if four == four:\n",
    "        text.append(str(four) + ' for 4+ family (total)')\n",
    "    if four_ == four_:\n",
    "        text.append(str(four_) + ' for 2+ family (per studio/1br)')\n",
    "\n",
    "    return '; '.join(text)\n",
    "\n",
    "#TODO: Clean Data\n",
    "zoning['PK'] = zoning.apply(parking_text, axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b138b17",
   "metadata": {},
   "source": [
    "### Combine GIS and zoning data on the `id` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7896edb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "final = combined_df.merge(\n",
    "    zoning,\n",
    "    on='id',\n",
    "    how='left',\n",
    "    suffixes=('', '_from_zoning')\n",
    ")\n",
    "\n",
    "zoning.drop(columns=['id'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3058ef5b",
   "metadata": {},
   "source": [
    "### Define the `overlay()` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e15cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given jurisdiction name and abbreviated district name,\n",
    "# combine zoning regulations from base district and overlay district (has priority)\n",
    "# If no base or overlay name are given, deduce from zone using `sep` as a separator between base and overlay\n",
    "# For example, R-10/RM represents a base of R-10 and an overlay of RM\n",
    "def overlay(j, ad, base=None, overlay=None, sep='/'):\n",
    "    \n",
    "    if not base:\n",
    "        base = ad.split(sep)[0].strip()\n",
    "        \n",
    "    if not overlay:\n",
    "        overlay = ad.split(sep)[1].strip()\n",
    "    \n",
    "    col_from = 'Type of Zoning District'\n",
    "    col_to = 'PK' # Parking text column created above\n",
    "    \n",
    "    # Get proper zoning values from the spreadsheet\n",
    "    base_values = zoning.loc[ zoning.Jurisdiction.eq(j) & zoning.AbbreviatedDistrict.eq(base), col_from : col_to ].values\n",
    "    overlay_values = zoning.loc[ zoning.Jurisdiction.eq(j) & zoning.AbbreviatedDistrict.eq(overlay), col_from : col_to ].values\n",
    "    \n",
    "    if len(base_values) != 1:\n",
    "        print(f'Base layer {base} in {j} does not exist, or is not unique!')\n",
    "        return\n",
    "     \n",
    "    if len(overlay_values) != 1:\n",
    "        print(f'Overlay layer {overlay} in {j} does not exist, or is not unique!')\n",
    "        return\n",
    "    \n",
    "    \n",
    "    base_values = base_values[0]\n",
    "    overlay_values = overlay_values[0]\n",
    "    \n",
    "    combined_values = [ o if (o == o and o !='' and o != 'Overlay')\n",
    "                            else b for b, o in zip(base_values, overlay_values) ]\n",
    "\n",
    "    final.loc[ final.Jurisdiction.eq(j) & final.AbbreviatedDistrict.eq(ad), col_from : col_to ] = combined_values\n",
    "    final.loc[ final.Jurisdiction.eq(j) & final.AbbreviatedDistrict.eq(ad), 'Jurisdiction' ] = j\n",
    "    final.loc[ final.Jurisdiction.eq(j) & final.AbbreviatedDistrict.eq(ad), 'AbbreviatedDistrict' ] = base + '/' + overlay\n",
    "    \n",
    "    # Update full district name\n",
    "    final.loc[ final['Jurisdiction'].eq(j) & final['AbbreviatedDistrict'].eq(ad), 'Full District Name' ] = zoning.loc[\n",
    "        zoning.Jurisdiction.eq(j) & zoning.AbbreviatedDistrict.eq(base), 'Full District Name'].iloc[0] + '/' + zoning.loc[\n",
    "        zoning.Jurisdiction.eq(j) & zoning.AbbreviatedDistrict.eq(overlay), 'Full District Name'].iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00303bc8",
   "metadata": {},
   "source": [
    "### Run `overlay()` on each zone that has an overlay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07fff11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For example:\n",
    "# \n",
    "# overlay('Bristol', 'R-10/RM')\n",
    "# overlay('Hartford', 'NX-1/Campus Overlay', 'NX-#', 'Campus Overlay')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60340350",
   "metadata": {},
   "source": [
    "### Account for non-defined zones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d661170",
   "metadata": {},
   "outputs": [],
   "source": [
    "final.loc[ final.AbbreviatedDistrict.isin(['NULL', 'Not Zoned']), 'AbbreviatedDistrict' ] = 'Not Zoned'\n",
    "final.loc[ final.AbbreviatedDistrict.isin(['NULL', 'Not Zoned']), 'Full District Name' ] = 'Not Zoned'\n",
    "final.loc[ final.AbbreviatedDistrict.isin(['NULL', 'Not Zoned']), 'Type of Zoning District' ] = 'Nonresidential'\n",
    "\n",
    "final.loc[ final.AbbreviatedDistrict.eq('Not Zoned'), 'MunicipalAcres' ] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0f3b6b",
   "metadata": {},
   "source": [
    "### Define column names to shorten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb8e838",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column names to shorten\n",
    "cols_xwalk = {\n",
    "    \n",
    "    # Basic district info\n",
    "    'Jurisdiction': 'T',\n",
    "    'Full District Name': 'Z',\n",
    "    'Type of Zoning District': 'Ty',\n",
    "    'MunicipalAcres': 'MA',\n",
    "    \n",
    "    # Type of homes allowed\n",
    "    '1-Family Treatment': '1F',\n",
    "    '2-Family Treatment': '2F',\n",
    "    '3-Family Treatment': '3F',\n",
    "    '4+-Family Treatment': '4F',\n",
    "    'Accessory Dwelling Unit (ADU) Treatment': 'AD',\n",
    "    \n",
    "    # Elderly housing\n",
    "    '1E': '1E',\n",
    "    '2E': '2E',\n",
    "    '3E': '3E',\n",
    "    '4E': '4E',\n",
    "    \n",
    "    # Minimum unit size requirement\n",
    "    '1MUS': '1MUS',\n",
    "    '2MUS': '2MUS',\n",
    "    '3MUS': '3MUS',\n",
    "    '4MUS': '4MUS',\n",
    "    'MUS': 'MUS', # any MUS for tooltip\n",
    "    \n",
    "    # Mininum lot size requirement\n",
    "    '1MLS': '1MLS',\n",
    "    '2MLS': '2MLS',\n",
    "    '3MLS': '3MLS',\n",
    "    '4MLS': '4MLS',\n",
    "    \n",
    "    # Affordable/Elderly only\n",
    "    'Affordable Housing District': 'AHD',\n",
    "    'Elderly Housing District': 'EHD',\n",
    "    \n",
    "    # Accessory Dwelling Units restrictions\n",
    "    'ADU Restricted to ONLY Primary Structure (i.e., No Outbuildings like Garages)': 'APrim',\n",
    "    'AduMaxSizeLimit': 'ASize',\n",
    "    'ADU Prohibition on Rental': 'ARent',\n",
    "    'ADU Employees or Family Only': 'AFam',\n",
    "    'ADU Owner Occupancy Required': 'AOwn',\n",
    "    'AEld': 'AEld', # created above\n",
    "    \n",
    "    # Tooltip notes\n",
    "    'Tooltip Notes': 'TN',\n",
    "}\n",
    "\n",
    "# Values to shorten\n",
    "vals_xwalk = {\n",
    "    'Allowed/Conditional': 'A',\n",
    "    'Special Permit': 'AH',\n",
    "    'Prohibited': 'N',\n",
    "    \n",
    "    'Primarily Residential': 'R',\n",
    "    'Mixed with Residential': 'M',\n",
    "    'No Residential': 'N',\n",
    "    'Nonresidential': 'N'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe563ec",
   "metadata": {},
   "source": [
    "# Save as GeoJSON\n",
    "\n",
    "This file is to be used in the web map. You can further use [`minify-geojson`](https://www.npmjs.com/package/minify-geojson) to compress the file to make it load faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3086505",
   "metadata": {},
   "outputs": [],
   "source": [
    "(final\n",
    "    .filter( list(cols_xwalk.keys()) + ['geometry'] )\n",
    "    .rename(columns=cols_xwalk)\n",
    "    .replace( vals_xwalk )\n",
    "    .assign(geometry=lambda df_: df_.geometry.simplify(0.00004))\n",
    "    .to_file('../data-pipeline/final.geojson', driver='GeoJSON')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b741bb5",
   "metadata": {},
   "source": [
    "### Save as CSV\n",
    "This file can then be used to calculate jurisdiction-level statistics and perform analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e95b0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "(final\n",
    " .filter([x for x in final.columns if x != 'geometry'])\n",
    " .to_csv('../data-pipeline/final.csv')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7785b275",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd05a623",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb17053",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a33807",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af431a87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58598fa7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5221d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "09bf152b664f50f765e4bcfe50e6ebaa1e5932f99a9f5db1b766ad61875f3f02"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
